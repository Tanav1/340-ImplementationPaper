{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# mount my google drive to this notebook so I can access my files\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kM_vS4u93d2H",
        "outputId": "293e11f0-4ee5-457b-f1ae-bd6d1030b9ed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "M9_-XS9N5hhO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Stroke_Prediction/healthcare-dataset-stroke-data.csv\")\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Stroke_Prediction/train_2v.csv\")\n",
        "\n",
        "\n",
        "# https://www.kaggle.com/datasets/shashwatwork/dementia-prediction-dataset"
      ],
      "metadata": {
        "id": "tFEzzWvk5TDC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = df.dropna()\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "\n",
        "df['gender'] = le.fit_transform(df.gender.values)\n",
        "df['ever_married'] = le.fit_transform(df.ever_married.values)\n",
        "df['work_type'] = le.fit_transform(df.work_type.values)\n",
        "df['Residence_type'] = le.fit_transform(df.Residence_type.values)\n",
        "df['smoking_status'] = le.fit_transform(df.smoking_status.values)\n"
      ],
      "metadata": {
        "id": "ND-2wPOI5dTn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2272a05b-e317-457d-dfc3-9bcea1fe8536"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-caf744545047>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['gender'] = le.fit_transform(df.gender.values)\n",
            "<ipython-input-16-caf744545047>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['ever_married'] = le.fit_transform(df.ever_married.values)\n",
            "<ipython-input-16-caf744545047>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['work_type'] = le.fit_transform(df.work_type.values)\n",
            "<ipython-input-16-caf744545047>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Residence_type'] = le.fit_transform(df.Residence_type.values)\n",
            "<ipython-input-16-caf744545047>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['smoking_status'] = le.fit_transform(df.smoking_status.values)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['gender', 'age', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'avg_glucose_level', 'bmi', 'smoking_status']]\n",
        "y = df['stroke']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = .3, random_state = 0)\n"
      ],
      "metadata": {
        "id": "UbfWvtmI5LOQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def metrics(y_pred, y_true):\n",
        "    _confusion_matrix = confusion_matrix(y_pred, y_true)\n",
        "    tp = _confusion_matrix[0,0]\n",
        "    fn = _confusion_matrix[1,0]\n",
        "    fp = _confusion_matrix[0,1]\n",
        "    tn = _confusion_matrix[1,1]\n",
        "    # metrics\n",
        "    precision = tp/(tp+fp)\n",
        "    recall = tp/(tp+fn)\n",
        "    fscore = 2*tp/(2*tp + fp + fn)\n",
        "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
        "    miss_rate = fn/(tn+tp)\n",
        "    fall_out_rate = fp/(fp+tn)\n",
        "    # return \n",
        "    return [precision, recall, fscore, accuracy, miss_rate, fall_out_rate]\n",
        "\n",
        "\n",
        "    \n",
        "# path = './dataset/train_2v.csv'\n",
        "# df = pd.read_csv(path)\n",
        "# df_clear = df.dropna(axis=0)\n",
        "# df_dict = df_clear.to_dict()\n",
        "# heads = list(df_dict.keys())\n",
        "# df_list = to_list(df_dict, heads)\n",
        "need_encoded = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
        "# MLP \n",
        "n_repeat = 5\n",
        "_metrics = []\n"
      ],
      "metadata": {
        "id": "cphpRuRK3ext"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path = './dataset/train_2v.csv'\n",
        "# df = pd.read_csv(path)\n",
        "# df_clear = df.dropna(axis=0)\n",
        "# df_dict = df_clear.to_dict()\n",
        "# heads = list(df_dict.keys())\n",
        "# df_list = to_list(df_dict, heads)\n",
        "need_encoded = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']"
      ],
      "metadata": {
        "id": "5GIsr2yMhqkY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP \n",
        "n_repeat = 5\n",
        "_metrics = []\n",
        "\n",
        "for i in range(n_repeat):\n",
        "    # generate data\n",
        "    seed = random.randint(1, 1000)\n",
        "    # inputs, targets = preprocess_data(df_list, need_encoded)\n",
        "    # inputs, targets = prepare_data(inputs, targets, seed)\n",
        "    # n_samples = inputs.shape[0]\n",
        "    # tr_inputs = inputs[0:int(n_samples*0.7), :]\n",
        "    # tr_targets = targets[0:int(n_samples*0.7)]\n",
        "    # te_inputs = inputs[int(n_samples*0.7):, :]\n",
        "    # te_targets = targets[int(n_samples*0.7):]\n",
        "    # # train clf\n",
        "    clf = MLPClassifier(learning_rate_init=1e-2,\n",
        "        solver='sgd',activation='relu',max_iter=500,\n",
        "        alpha=5e-4, hidden_layer_sizes=(16, 32, 16),random_state=1)\n",
        "    clf.fit(X_train, y_train)\n",
        "    # evaluate clf\n",
        "    te_pred = clf.predict(X_test)\n",
        "    run_metrics = metrics(te_pred, y_test)\n",
        "    print(i+1, \"complete\", run_metrics)\n",
        "\n",
        "\n",
        "    # run_metrics = metrics(te_pred, te_targets)\n",
        "    # print(i+1, \"complete\", run_metrics)\n",
        "    # _metrics.append(run_metrics)\n",
        "\n",
        "# _metrics = np.array(_metrics)\n",
        "# _metrics = np.mean(_metrics, axis=0)\n",
        "# # [precision, recall, fscore, accuracy, miss_rate, fall_out_rate]\n",
        "# print(_metrics)"
      ],
      "metadata": {
        "id": "MB4Hzd7h3cAG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92a7776a-3048-4991-b78e-f523c081d265"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 complete [0.979706489337308, 1.0, 0.9897492326402966, 0.979706489337308, 0.0, 1.0]\n",
            "2 complete [0.979706489337308, 1.0, 0.9897492326402966, 0.979706489337308, 0.0, 1.0]\n",
            "3 complete [0.979706489337308, 1.0, 0.9897492326402966, 0.979706489337308, 0.0, 1.0]\n",
            "4 complete [0.979706489337308, 1.0, 0.9897492326402966, 0.979706489337308, 0.0, 1.0]\n",
            "5 complete [0.979706489337308, 1.0, 0.9897492326402966, 0.979706489337308, 0.0, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "txB1zyxV5UzK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QQ4itdr-GW3w"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8cQE_iQfGfXV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}